---
permalink: /
title: "Yanbo Fang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a NLP Data Scientist and graduated from Rutgers with a master degree. I am focusing on Natural Language Processing and Machine Learning, and I worked with [Prof. Yongfeng Zhang](http://yongfeng.me/) and [Prof. Gerard de Melo](http://gerard.demelo.org/index.html#).

[Resume]([https://drive.google.com/file/d/1_YvS4Oyel2ecMTyolz1GKGR5OLhE86yl/view?usp=sharing](https://drive.google.com/file/d/1SmIAPy-wDFSG7H1snNGmqJtuWjkaPmpI/view?usp=drive_link))\\
[Research Statement](https://drive.google.com/file/d/1Ith3j3El0XQ7mVyEgQBEgkMtMC7u1XXf/view?usp=sharing)

I am mainly interested in the following NLP/AI research questions:
* **Understanding Learning Mechanism of LLMs**\\
  Understanding LLMs is crucial in harnessing their potential and mitigating their limitations. A key question in this domain is how to identify capacities these models have acquired? Furthermore, explainability in LLMs is a key aspect of trustworthy interpretation. It involves developing methods to make the decision-making process of these models transparent and understandable to humans. How do we trustworthly interprete model outputs?

* **Making LLMs to Tackle Unforseen Challenges**\\
  Acquiring comprehensive data covering all possible scenarios is an infeasible target. Therefore, it becomes imperative for LLMs to possess the ability to adapt and generalize their problem-solving skills in critical situations. Is it possible for LLMs to develop creative thinking when confronted with complex inquiries? What methods can be employed to enhance the creative capacities of LLMs and drive breakthroughs? Is it plausible for these models, adhering to the [_minority rules_](https://en.wikipedia.org/wiki/Minoritarianism) to learn from outliers and potentially challenge established paradigms, or even facilitate paradigm shifts to align with emerging situations?

* **Exploring the Impacts of LLMs on Society**
  It is widely expected that AI will become deeply integrated into our daily lives. Is it possible to find a synergistic approach, where human judgment is combined with the LLMs' computational power, could lead to more effective and responsible use of technologies? It's notable that these models ofen generate generic, indistinguishable responses to similar questions with varying conditions. If social media platforms become saturated with such homogeneous content, would it accelerate or impede meaningful human contemplation?