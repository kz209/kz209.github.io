---
permalink: /
title: "Yanbo Fang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Welcome to my webpage! I am currently a NLP Data Scientist. I am focusing on Natural Language Processing and Machine Learning, and I worked with [Prof. Yongfeng Zhang](http://yongfeng.me/) and [Prof. Gerard de Melo](http://gerard.demelo.org/index.html#).\\\\

[Resume]([https://drive.google.com/file/d/1_YvS4Oyel2ecMTyolz1GKGR5OLhE86yl/view?usp=sharing](https://drive.google.com/file/d/1SmIAPy-wDFSG7H1snNGmqJtuWjkaPmpI/view?usp=drive_link))\\

[Research Statement](https://drive.google.com/file/d/1Ith3j3El0XQ7mVyEgQBEgkMtMC7u1XXf/view?usp=sharing)

I am mainly interested in the following NLP/AI research questions:
* **Understanding Learning Mechanism of LLMs**: Understanding LLMs is crucial in harnessing their potential and mitigating their limitations. A key question in this domain is how to identify capacities these models have acquired? Furthermore, explainability in LLMs is a key aspect of trustworthy interpretation. It involves developing methods to make the decision-making process of these models transparent and understandable to humans. How do we trustworthly interprete model outputs?

* **Making LLMs to Tackle Unforseen Challenges**: Acquiring comprehensive data to cover all possible scenarios is an infeasible target. Therefore,  it becomes imperative for LLMs to possess the ability to adapt and generalize their problem-solving skills in critical situations. Is it possible for LLMs to develop creative thinking when confronted with complex inquiries? What methods can be employed to enhance the creative capacities of LLMs and drive breakthroughs in human knowledge? Is it plausible for these models, adhering to the [_minority rules_](https://en.wikipedia.org/wiki/Minoritarianism) to learn from outliers and potentially challenge established paradigms from training, or even facilitate paradigm shifts to align with emerging circumstances?

* **Exploring the Impacts of LLMs on Society**: It is widely anticipated that AI systems will become deeply integrated into our daily lives in the near future. Is it possible to find a synergistic approach, where human judgment is combined with the computational power of LLMs, could lead to more effective and responsible use of these technologies? It's notable that these models ofen generate generic, indistinguishable responses to similar questions with varying conditions. If social media platforms become saturated with such homogeneous content, would it accelerate or impede meaningful human contemplation?